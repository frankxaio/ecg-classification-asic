{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a15f5cc-7d64-4b6f-b472-6a55064c1267",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37c8fd-cb88-4730-acbd-59c8e57ac3db",
   "metadata": {},
   "source": [
    "## 參數的邊界\n",
    "將每一層的 weight, bias, scale 印出來 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ac6317-3b51-4176-a4a3-b159e0825c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+-----------+---------------+---------------+--------------------+\n",
      "| File                                                          | Type      | Minimum Value | Maximum Value | Max Weight * Scale |\n",
      "+---------------------------------------------------------------+-----------+---------------+---------------+--------------------+\n",
      "| \\classifier_1_pk\\quantization_scale.txt                       | Scale     |    0.00233354 |    0.00233354 |                  - |\n",
      "| \\classifier_1_pk\\quantized_bias.txt                           | Bias      |    0.05804596 |     0.1120506 |                  - |\n",
      "| \\classifier_1_pk\\quantized_weights.txt                        | Weight    |        -128.0 |         112.0 |           0.261356 |\n",
      "| \\embedding_0_pk\\quantization_scale.txt                        | Scale     |    0.00993039 |    0.00993039 |                  - |\n",
      "| \\embedding_0_pk\\quantized_bias.txt                            | Bias      |   -0.99623609 |    0.93710607 |                  - |\n",
      "| \\embedding_0_pk\\quantized_weights.txt                         | Weight    |        -128.0 |         126.0 |           1.251229 |\n",
      "| \\embedding_cls_token\\parameters.txt                           | Parameter |   -2.27609324 |    2.50277138 |                  - |\n",
      "| encoder_0_0_block_0_final_pk\\quantization_scale.txt           | Scale     |     0.0029745 |     0.0029745 |                  - |\n",
      "| encoder_0_0_block_0_final_pk\\quantized_bias.txt               | Bias      |   -0.11742528 |    0.16070758 |                  - |\n",
      "| encoder_0_0_block_0_final_pk\\quantized_weights.txt            | Weight    |        -121.0 |         127.0 |           0.377762 |\n",
      "| encoder_0_0_block_0_keys_pk\\quantization_scale.txt            | Scale     |     0.0028165 |     0.0028165 |                  - |\n",
      "| encoder_0_0_block_0_keys_pk\\quantized_bias.txt                | Bias      |   -0.18648292 |    0.16569334 |                  - |\n",
      "| encoder_0_0_block_0_keys_pk\\quantized_weights.txt             | Weight    |        -112.0 |         127.0 |           0.357695 |\n",
      "| encoder_0_0_block_0_queries_pk\\quantization_scale.txt         | Scale     |    0.00275813 |    0.00275813 |                  - |\n",
      "| encoder_0_0_block_0_queries_pk\\quantized_bias.txt             | Bias      |    -0.1221425 |      0.133846 |                  - |\n",
      "| encoder_0_0_block_0_queries_pk\\quantized_weights.txt          | Weight    |        -108.0 |         127.0 |           0.350283 |\n",
      "| encoder_0_0_block_0_values_pk\\quantization_scale.txt          | Scale     |    0.00412028 |    0.00412028 |                  - |\n",
      "| encoder_0_0_block_0_values_pk\\quantized_bias.txt              | Bias      |   -0.11580569 |    0.12183636 |                  - |\n",
      "| encoder_0_0_block_0_values_pk\\quantized_weights.txt           | Weight    |        -128.0 |         126.0 |           0.519155 |\n",
      "| encoder_0_1_block_0_0_pk\\quantization_scale.txt               | Scale     |    0.00336775 |    0.00336775 |                  - |\n",
      "| encoder_0_1_block_0_0_pk\\quantized_bias.txt                   | Bias      |   -0.18774113 |    0.15236326 |                  - |\n",
      "| encoder_0_1_block_0_0_pk\\quantized_weights.txt                | Weight    |        -128.0 |          73.0 |           0.245846 |\n",
      "| encoder_0_1_block_0_2_pk\\quantization_scale.txt               | Scale     |     0.0015017 |     0.0015017 |                  - |\n",
      "| encoder_0_1_block_0_2_pk\\quantized_bias.txt                   | Bias      |   -0.13292247 |    0.12008531 |                  - |\n",
      "| encoder_0_1_block_0_2_pk\\quantized_weights.txt                | Weight    |        -125.0 |         127.0 |           0.190716 |\n",
      "| positional_encoding_params\\positional_encoding\\parameters.txt | Parameter |   -3.48093176 |    3.64265108 |                  - |\n",
      "+---------------------------------------------------------------+-----------+---------------+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def read_values_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        values = [float(line.strip()) for line in file]\n",
    "    return values\n",
    "\n",
    "def find_min_max_values(folder_path, output_file):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"File\", \"Type\", \"Minimum Value\", \"Maximum Value\", \"Max Weight * Scale\"]\n",
    "    table.align[\"File\"] = \"l\"\n",
    "    table.align[\"Type\"] = \"l\"\n",
    "    table.align[\"Minimum Value\"] = \"r\" \n",
    "    table.align[\"Maximum Value\"] = \"r\"\n",
    "    table.align[\"Max Weight * Scale\"] = \"r\"\n",
    "\n",
    "    base_path = os.path.join(folder_path, '')\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        max_weight_scale = float('-inf')\n",
    "        for file in files:\n",
    "            if file in ['quantized_weights.txt', 'quantized_bias.txt', 'quantization_scale.txt', 'parameters.txt']:\n",
    "                file_path = os.path.join(root, file)\n",
    "                values = read_values_from_file(file_path)\n",
    "                min_value = min(values)\n",
    "                max_value = max(values)\n",
    "                relative_path = file_path.replace(base_path, '').replace('__packed_params__packed_params', '_pk').replace('_projection', '')\n",
    "                \n",
    "                if file == 'quantized_weights.txt':\n",
    "                    value_type = 'Weight'\n",
    "                    scale_file = os.path.join(root, 'quantization_scale.txt')\n",
    "                    if os.path.exists(scale_file):\n",
    "                        scale = read_values_from_file(scale_file)[0]\n",
    "                        max_weight_scale = max(max_weight_scale, max_value * scale)\n",
    "                elif file == 'quantized_bias.txt':\n",
    "                    value_type = 'Bias'\n",
    "                elif file == 'quantization_scale.txt':\n",
    "                    value_type = 'Scale'\n",
    "                else:\n",
    "                    value_type = 'Parameter'\n",
    "                \n",
    "                display_path = relative_path\n",
    "                for x in [\"encoder_0_params\\\\\", \"embedding_params\", \"classifier_params\"]:\n",
    "                    display_path = display_path.replace(x, '')\n",
    "                \n",
    "                table.add_row([display_path, value_type, min_value, max_value, f'{max_weight_scale:.6f}' if value_type == 'Weight' else '-'])\n",
    "\n",
    "    print(table)\n",
    "\n",
    "    with open(output_file, 'w') as out_file:\n",
    "        out_file.write(str(table))\n",
    "\n",
    "# Specify the path to the folder containing the quantized model\n",
    "folder_path = '32float_quantized'\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = 'min_max_values.txt'\n",
    "\n",
    "# Call the function to find the minimum and maximum values and write to file\n",
    "find_min_max_values(folder_path, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a70971-a8f2-4f52-9ab6-a87188c626b6",
   "metadata": {},
   "source": [
    "## Convert to binary\n",
    "觀察上表可以發現，Bias, scale 的值落在 -1~1 之間，所以用~~完全小數表示~~，要使用\n",
    "\n",
    "**`Linear`**\n",
    "- Scale: 16-bit, 1-bit integer part + 15-bit fraction part\n",
    "- Bias: 16-bit, 1-bit integer part + 15-bit fraction part\n",
    "- Weight: 8-bit, 2-bit integer, 6-bit fraction\n",
    "\n",
    "**`cls_token`, `positional_encoding`**\n",
    "\n",
    "16-bit, 4-bit integer part, 12-bit fraction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a474bea-7ca9-4b71-9b41-e9a40d2fe35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def float_to_fixed16(float_value, integer_bits, fraction_bits):\n",
    "    # Convert float to 16-bit fixed-point representation with specified integer and fraction bits\n",
    "    fixed16_value = int(round(float_value * (2**fraction_bits)))\n",
    "    if fixed16_value < 0:\n",
    "        fixed16_value = (abs(fixed16_value) ^ 0xFFFF) + 1\n",
    "    binary = format(fixed16_value & 0xFFFF, '016b')\n",
    "    return binary\n",
    "\n",
    "def process_file(file_path, output_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        processed_lines = []\n",
    "        for line in lines:\n",
    "            try:\n",
    "                value = float(line.strip())\n",
    "                if file_path.endswith('_bias.txt'):\n",
    "                    # Convert bias values to 16-bit fixed-point with 1-bit integer and 15-bit fraction\n",
    "                    fixed16_binary = float_to_fixed16(value, 1, 15)\n",
    "                    processed_lines.append(fixed16_binary + '\\n')\n",
    "                elif file_path.endswith('quantization_scale.txt'):\n",
    "                    # Convert quantization_scale values to 16-bit fixed-point with 1-bit integer and 15-bit fraction\n",
    "                    fixed16_binary = float_to_fixed16(value, 1, 15)\n",
    "                    processed_lines.append(fixed16_binary + '\\n')\n",
    "                elif 'embedding_cls_token' in file_path or 'positional_encoding' in file_path:\n",
    "                    # Convert embedding_cls_token and positional_encoding values to 16-bit fixed-point with 4-bit integer and 12-bit fraction\n",
    "                    fixed16_binary = float_to_fixed16(value, 4, 12)\n",
    "                    processed_lines.append(fixed16_binary + '\\n')\n",
    "                elif value.is_integer():\n",
    "                    # Convert integer to two's complement representation\n",
    "                    integer = int(value)\n",
    "                    if integer < 0:\n",
    "                        integer = (~abs(integer) + 1) & 0xFF\n",
    "                    processed_lines.append(format(integer, '08b') + '\\n')\n",
    "                else:\n",
    "                    # Convert float to 8-bit fixed-point representation with 1-bit integer and 7-bit fraction\n",
    "                    fixed8_value = int(round(value * (2**7)))\n",
    "                    if fixed8_value < 0:\n",
    "                        fixed8_value = (~abs(fixed8_value) + 1) & 0xFF\n",
    "                    processed_lines.append(format(fixed8_value, '08b') + '\\n')\n",
    "            except ValueError:\n",
    "                processed_lines.append(line)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.writelines(processed_lines)\n",
    "\n",
    "def process_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                input_file_path = os.path.join(root, file)\n",
    "                output_file_path = os.path.join(output_directory, os.path.relpath(input_file_path, input_directory))\n",
    "                process_file(input_file_path, output_file_path)\n",
    "\n",
    "# Specify the path to the input directory (32float_quantized)\n",
    "input_directory = '32float_quantized'\n",
    "# Specify the path to the output directory (8bit_fixed_point)\n",
    "output_directory = '8bit_fixed_point'\n",
    "\n",
    "# Process all .txt files in the input directory and its subdirectories\n",
    "process_directory(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
