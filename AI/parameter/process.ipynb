{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a15f5cc-7d64-4b6f-b472-6a55064c1267",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37c8fd-cb88-4730-acbd-59c8e57ac3db",
   "metadata": {},
   "source": [
    "將每一層的 weight, bias, scale 印出來 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ac6317-3b51-4176-a4a3-b159e0825c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+-----------+---------------+---------------+--------------------+\n",
      "| File                                                          | Type      | Minimum Value | Maximum Value | Max Weight * Scale |\n",
      "+---------------------------------------------------------------+-----------+---------------+---------------+--------------------+\n",
      "| \\classifier_1_pk\\quantization_scale.txt                       | Scale     |    0.00233354 |    0.00233354 |                  - |\n",
      "| \\classifier_1_pk\\quantized_bias.txt                           | Bias      |    0.05804596 |     0.1120506 |                  - |\n",
      "| \\classifier_1_pk\\quantized_weights.txt                        | Weight    |        -128.0 |         112.0 |           0.261356 |\n",
      "| \\embedding_0_pk\\quantization_scale.txt                        | Scale     |    0.00993039 |    0.00993039 |                  - |\n",
      "| \\embedding_0_pk\\quantized_bias.txt                            | Bias      |   -0.99623609 |    0.93710607 |                  - |\n",
      "| \\embedding_0_pk\\quantized_weights.txt                         | Weight    |        -128.0 |         126.0 |           1.251229 |\n",
      "| \\embedding_cls_token\\parameters.txt                           | Parameter |   -2.27609324 |    2.50277138 |                  - |\n",
      "| encoder_0_0_block_0_final_pk\\quantization_scale.txt           | Scale     |     0.0029745 |     0.0029745 |                  - |\n",
      "| encoder_0_0_block_0_final_pk\\quantized_bias.txt               | Bias      |   -0.11742528 |    0.16070758 |                  - |\n",
      "| encoder_0_0_block_0_final_pk\\quantized_weights.txt            | Weight    |        -121.0 |         127.0 |           0.377762 |\n",
      "| encoder_0_0_block_0_keys_pk\\quantization_scale.txt            | Scale     |     0.0028165 |     0.0028165 |                  - |\n",
      "| encoder_0_0_block_0_keys_pk\\quantized_bias.txt                | Bias      |   -0.18648292 |    0.16569334 |                  - |\n",
      "| encoder_0_0_block_0_keys_pk\\quantized_weights.txt             | Weight    |        -112.0 |         127.0 |           0.357695 |\n",
      "| encoder_0_0_block_0_queries_pk\\quantization_scale.txt         | Scale     |    0.00275813 |    0.00275813 |                  - |\n",
      "| encoder_0_0_block_0_queries_pk\\quantized_bias.txt             | Bias      |    -0.1221425 |      0.133846 |                  - |\n",
      "| encoder_0_0_block_0_queries_pk\\quantized_weights.txt          | Weight    |        -108.0 |         127.0 |           0.350283 |\n",
      "| encoder_0_0_block_0_values_pk\\quantization_scale.txt          | Scale     |    0.00412028 |    0.00412028 |                  - |\n",
      "| encoder_0_0_block_0_values_pk\\quantized_bias.txt              | Bias      |   -0.11580569 |    0.12183636 |                  - |\n",
      "| encoder_0_0_block_0_values_pk\\quantized_weights.txt           | Weight    |        -128.0 |         126.0 |           0.519155 |\n",
      "| encoder_0_1_block_0_0_pk\\quantization_scale.txt               | Scale     |    0.00336775 |    0.00336775 |                  - |\n",
      "| encoder_0_1_block_0_0_pk\\quantized_bias.txt                   | Bias      |   -0.18774113 |    0.15236326 |                  - |\n",
      "| encoder_0_1_block_0_0_pk\\quantized_weights.txt                | Weight    |        -128.0 |          73.0 |           0.245846 |\n",
      "| encoder_0_1_block_0_2_pk\\quantization_scale.txt               | Scale     |     0.0015017 |     0.0015017 |                  - |\n",
      "| encoder_0_1_block_0_2_pk\\quantized_bias.txt                   | Bias      |   -0.13292247 |    0.12008531 |                  - |\n",
      "| encoder_0_1_block_0_2_pk\\quantized_weights.txt                | Weight    |        -125.0 |         127.0 |           0.190716 |\n",
      "| positional_encoding_params\\positional_encoding\\parameters.txt | Parameter |   -3.48093176 |    3.64265108 |                  - |\n",
      "+---------------------------------------------------------------+-----------+---------------+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def read_values_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        values = [float(line.strip()) for line in file]\n",
    "    return values\n",
    "\n",
    "def find_min_max_values(folder_path, output_file):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"File\", \"Type\", \"Minimum Value\", \"Maximum Value\", \"Max Weight * Scale\"]\n",
    "    table.align[\"File\"] = \"l\"\n",
    "    table.align[\"Type\"] = \"l\"\n",
    "    table.align[\"Minimum Value\"] = \"r\" \n",
    "    table.align[\"Maximum Value\"] = \"r\"\n",
    "    table.align[\"Max Weight * Scale\"] = \"r\"\n",
    "\n",
    "    base_path = os.path.join(folder_path, '')\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        max_weight_scale = float('-inf')\n",
    "        for file in files:\n",
    "            if file in ['quantized_weights.txt', 'quantized_bias.txt', 'quantization_scale.txt', 'parameters.txt']:\n",
    "                file_path = os.path.join(root, file)\n",
    "                values = read_values_from_file(file_path)\n",
    "                min_value = min(values)\n",
    "                max_value = max(values)\n",
    "                relative_path = file_path.replace(base_path, '').replace('__packed_params__packed_params', '_pk').replace('_projection', '')\n",
    "                \n",
    "                if file == 'quantized_weights.txt':\n",
    "                    value_type = 'Weight'\n",
    "                    scale_file = os.path.join(root, 'quantization_scale.txt')\n",
    "                    if os.path.exists(scale_file):\n",
    "                        scale = read_values_from_file(scale_file)[0]\n",
    "                        max_weight_scale = max(max_weight_scale, max_value * scale)\n",
    "                elif file == 'quantized_bias.txt':\n",
    "                    value_type = 'Bias'\n",
    "                elif file == 'quantization_scale.txt':\n",
    "                    value_type = 'Scale'\n",
    "                else:\n",
    "                    value_type = 'Parameter'\n",
    "                \n",
    "                display_path = relative_path\n",
    "                for x in [\"encoder_0_params\\\\\", \"embedding_params\", \"classifier_params\"]:\n",
    "                    display_path = display_path.replace(x, '')\n",
    "                \n",
    "                table.add_row([display_path, value_type, min_value, max_value, f'{max_weight_scale:.6f}' if value_type == 'Weight' else '-'])\n",
    "\n",
    "    print(table)\n",
    "\n",
    "    with open(output_file, 'w') as out_file:\n",
    "        out_file.write(str(table))\n",
    "\n",
    "# Specify the path to the folder containing the quantized model\n",
    "folder_path = '32float_quantized'\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = 'min_max_values.txt'\n",
    "\n",
    "# Call the function to find the minimum and maximum values and write to file\n",
    "find_min_max_values(folder_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a474bea-7ca9-4b71-9b41-e9a40d2fe35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def float_to_fixed8(float_value):\n",
    "    # Convert float to 16-bit floating-point representation\n",
    "    float16 = int(float_value * (2**10))\n",
    "\n",
    "    # Extract the sign, exponent, and mantissa from the 16-bit floating-point number\n",
    "    sign = (float16 >> 15) & 0x1\n",
    "    exponent = (float16 >> 10) & 0x1F\n",
    "    mantissa = float16 & 0x3FF\n",
    "\n",
    "    # Calculate the actual exponent by subtracting the bias (15 for half-precision)\n",
    "    actual_exponent = exponent - 15\n",
    "\n",
    "    # Shift the mantissa to the left by the actual exponent\n",
    "    fixed_point = (mantissa | 0x400) << actual_exponent\n",
    "\n",
    "    # Extract the integer and fraction parts\n",
    "    integer_part = (fixed_point >> 10) & 0x3\n",
    "    fraction_part = (fixed_point >> 4) & 0x3F\n",
    "\n",
    "    # Combine the sign, integer part, and fraction part into an 8-bit fixed-point number\n",
    "    fixed8 = (sign << 7) | (integer_part << 6) | fraction_part\n",
    "\n",
    "    # Convert the fixed8 number to two's complement representation\n",
    "    if sign == 1:\n",
    "        fixed8 = (~fixed8 + 1) & 0xFF\n",
    "\n",
    "    # Convert the fixed8 number to binary representation\n",
    "    binary = format(fixed8, '08b')\n",
    "\n",
    "    return binary\n",
    "\n",
    "\n",
    "def process_file(file_path, output_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        processed_lines = []\n",
    "        for line in lines:\n",
    "            try:\n",
    "                value = float(line.strip())\n",
    "                if file_path.endswith('_bias.txt') or \"embedding_cls_token\" in file_path:\n",
    "                    # Convert bias values, embedding_cls_token values, or quantization_scale values to 8-bit fixed-point with 6-bit fraction\n",
    "                    fixed8_value = int(value * (2**6))\n",
    "                    if fixed8_value < 0:\n",
    "                        fixed8_value = (~abs(fixed8_value) + 1) & 0xFF\n",
    "                    processed_lines.append(format(fixed8_value, '08b') + '\\n')\n",
    "                elif value.is_integer():\n",
    "                    # Convert integer to two's complement representation\n",
    "                    integer = int(value)\n",
    "                    if integer < 0:\n",
    "                        integer = (~abs(integer) + 1) & 0xFF\n",
    "                    processed_lines.append(format(integer, '08b') + '\\n')\n",
    "                else:\n",
    "                    fixed8_binary = float_to_fixed8(value)\n",
    "                    processed_lines.append(fixed8_binary + '\\n')\n",
    "            except ValueError:\n",
    "                processed_lines.append(line)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.writelines(processed_lines)\n",
    "\n",
    "def process_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                input_file_path = os.path.join(root, file)\n",
    "                output_file_path = os.path.join(output_directory, os.path.relpath(input_file_path, input_directory))\n",
    "                process_file(input_file_path, output_file_path)\n",
    "\n",
    "# Specify the path to the input directory (32float_quantized)\n",
    "input_directory = '32float_quantized'\n",
    "\n",
    "# Specify the path to the output directory (8bit_fixed_point)\n",
    "output_directory = '8bit_fixed_point'\n",
    "\n",
    "# Process all .txt files in the input directory and its subdirectories\n",
    "process_directory(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
